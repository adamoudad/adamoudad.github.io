<!doctype html>
<html lang="en-us">
  <head>
    <title>Word embeddings with sound // Adam Oudad</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.57.2" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Adam Oudad" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://adamoudad.github.io/css/main.min.59023e5fd38d6ecb0e1dfbb295077c3c67e00e3b9eb3feaf34b5a5e6b332897a.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Word embeddings with sound"/>
<meta name="twitter:description" content="I came across this article called Sound-Word2Vec:Learning Word Representations Grounded in Sounds1, which caught my attention as it aims at creating word embeddings in an original way, using voiced sounds of words. What is embedding   Embedding in Machine Learning refers to a method for capturing the information of an input data into a dense representation. This way, we obtain an embedding space, which should have interesting properties like being friendly to vector arithmetics, which is not the case of original raw data."/>

    <meta property="og:title" content="Word embeddings with sound" />
<meta property="og:description" content="I came across this article called Sound-Word2Vec:Learning Word Representations Grounded in Sounds1, which caught my attention as it aims at creating word embeddings in an original way, using voiced sounds of words. What is embedding   Embedding in Machine Learning refers to a method for capturing the information of an input data into a dense representation. This way, we obtain an embedding space, which should have interesting properties like being friendly to vector arithmetics, which is not the case of original raw data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adamoudad.github.io/post/sound-word2vec/" />
<meta property="article:published_time" content="2019-10-21T03:49:04+09:00" />
<meta property="article:modified_time" content="2019-10-21T03:49:04+09:00" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://adamoudad.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="Adam Oudad" /></a>
      <h1>Adam Oudad</h1>
      <p>Deep Learning, Natural Language Processing, Music Information Retrieval... and more!</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/adamoudad"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
          <a target="_blank" href="https://www.linkedin.com/in/adam-oudad-9436b866/"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-linkedin">
  <title>linkedin</title>
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Word embeddings with sound</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Oct 21, 2019
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          3 min read
        </div><div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
          <a class="tag" href="https://adamoudad.github.io/tags/nlp/">nlp</a><a class="tag" href="https://adamoudad.github.io/tags/embedding/">embedding</a></div></div>
    </header>
    <div class="post-content">
      
<p>
I came across this article called <a href="https://www.aclweb.org/anthology/D17-1096.pdf">Sound-Word2Vec:Learning Word Representations Grounded in Sounds</a><sup class="footnote-reference"><a id="footnote-reference-1" href="#footnote-1">1</a></sup>, which caught my attention as it aims at creating word embeddings in an original way, using voiced sounds of words.
</p>
<h1 id="headline-1">
What is embedding
</h1>
<p>
Embedding in Machine Learning refers to a method for capturing the information of an input data into a dense representation. This way, we obtain an embedding space, which should have interesting properties like being friendly to vector arithmetics, which is not the case of original raw data.
</p>
<p>
For example, one-hot encoding is somewhat a poor embedding method, as it encodes data into a sparse vector space, and interpolation will not work as expected. What I mean by &#34;as expected&#34; is, we would prefer our embedding space to relate distances between vectors to something interpretable, such as semantics (synonyms, antonyms, etc). For this, Word2Vec performs quite well.
</p>
<h1 id="headline-2">
What is the point of using sound ?
</h1>
<p>
Human language can be written and spoken. Embeddings grounded in sounds capture dependancies between words and onomatopeia.
It is important to give machines an insight on sound dependancies of words, therefore bridging the gap between natural language and speech.
</p>
<p>
In the research paper, sounds are clustered using various audio features, with K-means clustering. This is then considered as the target of the learning phase for the model.
</p>
<h1 id="headline-3">
Sound-Word2Vec model
</h1>
<p>
The model is similar to Word2Vec. A hidden layer is a fully-connected layer with softmax activation.
<img src="figure-1.png" alt="figure-1.png" title="figure-1.png" />
The task is simply to predict the sound cluster a given input word falls into. A Word2Vec pretrained model is used to take advantage of semantic information already contained in such embeddings. This is relatable to the technique of Transfer Learning, where the model is adapted to a new context, for performing better at sound-related tasks. Indeed, the model is therefore tested on three sound-related tasks:
</p>
<dl>
<dt>
Text-based sound retrieval<dd>
<p>
given a textual description, find a corresponding sound in the database
</p>
<dd>
<dt>
Foley sound discovery<dd>
<p>
Given an outline of describing the technique for producing a sound, find relevant words suitable for producing the same sound
</p>
<dd>
<dt>
Aurally relevant relatedness<dd>
<dd>
</dl>
<h1 id="headline-4">
Sound data
</h1>
<p>
Sound data was retrieved from <a href="http://www.freesound.org/">freesound.org</a>, a website collecting sounds uploaded by users. This represents a huge database of various tagged sounds with descriptions.
</p>
<h1 id="headline-5">
Nearest neighbors are sound-related
</h1>
<p>
The following table from the original paper show how such embeddings differ from Word2Vec&#39;s embeddings, which are semantically related. <em>apple</em> is associated with <em>bite</em>, <em>chew</em>, <em>munch</em>, instead of <em>fruit</em>, <em>pears</em>.
<img src="table-3.png" alt="table-3.png" title="table-3.png" />
</p>
<p>
Recall results on Text-based sound retrieval task are registered on the following table.
<img src="table-1.png" alt="table-1.png" title="table-1.png" />
</p>
<h1 id="headline-6">
Final words
</h1>
<p>
Embeddings are crucial in connectionist view of Machine Learning, as they present input information in a suitable form for subsequent task to perform. I can think of such embeddings being used for lyrics generation, speech recognition, or sentiment analysis. The goal of course is to get put as much information as you can in your embedding, so I believe bridging two fields like sound and natural language is the way to go if we want to obtain rich embeddings.
</p>
<h1 id="headline-7">
Footnotes
</h1>
<div class="footnotes">
<hr class="footnotes-separatator">
<div class="footnote-definitions">
<div class="footnote-definition">
<sup id="footnote-1"><a href="#footnote-reference-1">1</a></sup>
<div class="footnote-body">
<p>
Sound-Word2Vec:Learning Word Representations Grounded in Sounds, A. Vijayakumar, R Vedantam, D. Parikh, EMNLP conference 2017.
</p>
</div>
</div>
</div>
</div>

    </div>
    <div class="post-footer">
      <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "adamoudad-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
  </article>

    </main>
    </body>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css" integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js" integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js" integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>

</html>

