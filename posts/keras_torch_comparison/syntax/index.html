<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<title>Comparison of Keras and PyTorch syntaxes - (Machine) Learning log.</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="monetization" content="$ilp.uphold.com/iN8Xkq2iHNHB">


<meta name="generator" content="Hugo 0.99.1" /><meta itemprop="name" content="Comparison of Keras and PyTorch syntaxes">
<meta itemprop="description" content="Keras and PyTorch are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast. There are similar abstraction layers developped on top of PyTorch, such as PyTorch Ignite or PyTorch lightning. They are not yet as mature as Keras, but are worth the try!
 I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks."><meta itemprop="datePublished" content="2021-03-02T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-03-02T00:00:00+00:00" />
<meta itemprop="wordCount" content="1067">
<meta itemprop="keywords" content="machine-learning,pytorch,keras," /><meta property="og:title" content="Comparison of Keras and PyTorch syntaxes" />
<meta property="og:description" content="Keras and PyTorch are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast. There are similar abstraction layers developped on top of PyTorch, such as PyTorch Ignite or PyTorch lightning. They are not yet as mature as Keras, but are worth the try!
 I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adamoudad.github.io/posts/keras_torch_comparison/syntax/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-03-02T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Comparison of Keras and PyTorch syntaxes"/>
<meta name="twitter:description" content="Keras and PyTorch are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast. There are similar abstraction layers developped on top of PyTorch, such as PyTorch Ignite or PyTorch lightning. They are not yet as mature as Keras, but are worth the try!
 I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks."/>
<meta name="twitter:site" content="@OudadAdam"/>
<link rel="stylesheet" href="/css/bundle.min.262e62e9c1615dd1ac95d339cfc4ca2167aee72b71d853838920a22e7088b06b.css" integrity="sha256-Ji5i6cFhXdGsldM5z8TKIWeu5ytx2FODiSCiLnCIsGs=">
        <link rel="stylesheet" href="/css/add-on.css">
</head>

  <body>
    
<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/">
        
          
            posts
          
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu">
      
        
          
          
            <a href="/" class="link"><i class='fa fa-home'></i> Home</a>
          
        
      
        
          
          
            <a href="/about/" class="link"><i class='far fa-id-card'></i> About</a>
          
        
      
        
          
          
            <a href="/posts/" class="link"><i class='far fa-newspaper'></i> Posts</a>
          
        
      
        
          
          
            <a href="/categories/" class="link"><i class='fas fa-sitemap'></i> Categories</a>
          
        
      
      <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      

    </menu>
    

    <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="lang-menu" class="flyout-menu">
  <a href="#" lang="en" class="link active">English (en)</a>
  
    
      
        <a href="/fr" lang="fr" class="no-lang link">Français (fr)</a>
      
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes&amp;url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_torch_comparison%2fsyntax%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_torch_comparison%2fsyntax%2f&amp;title=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro" >
  <a href="/"><img src="/avatar.png" class="circle" width="150" alt="Adam Oudad" /></a>
  <header>
    <h1>Adam Oudad</h1>
  </header>
  <main>
    <p>(Machine) Learning log.</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/adamoudad" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/7013114/adam-oudad" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@adam.oudad" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//linkedin.com/in/adamoudad" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>















<li><a href="//twitter.com/OudadAdam" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>







<li><a href="//researchgate.net/profile/Adam_Oudad" target="_blank" rel="noopener" title="Research Gate"><i class="ai ai-researchgate"></i></a></li>





      </ul>
    </footer>
  
</section>

      <main id="site-main">
        <article class="post">
  <header>
  <div class="title">
    
        <h2><a href="/posts/keras_torch_comparison/syntax/">Comparison of Keras and PyTorch syntaxes</a></h2>
    
    
</div>
  <div class="meta">
    <time class="published" datetime="2021-03-02 00:00:00 &#43;0000 UTC">
      March 2, 2021
    </time>
    <span class="author"></span>
    
      <p>6 minutes read</p>
    
  </div>
</header>

  <section id="socnet-share">
    




  
    
    <a href="//twitter.com/share?text=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes&amp;url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_torch_comparison%2fsyntax%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_torch_comparison%2fsyntax%2f&amp;title=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  


  </section>
  

  <div class="content">
    
<p>
 <a href="https://keras.io/">Keras</a> and <a href="pytorch.org/">PyTorch</a> are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast.
 There are similar abstraction layers developped on top of <a href="https://pytorch.org/">PyTorch</a>, such as <a href="https://pytorch.org/ignite/">PyTorch Ignite</a> or <a href="https://github.com/PyTorchLightning/pytorch-lightning">PyTorch lightning</a>. They are not yet as mature as Keras, but are worth the try!</p>
<p>
I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks.
 This article is the first of a series. After comparing syntaxes in this article, I will demonstrate a practical example on sentiment classification comparing both frameworks in a subsequent article I will publish later this month.</p>
<div id="outline-container-headline-1" class="outline-2">
<h2 id="headline-1">
Prepare the data
</h2>
<div id="outline-text-headline-1" class="outline-text-2">
<p>The first comparison is on how data is loaded and prepared. Loading data can be achieved in a very similar fashion between both frameworks,  using <code>utils.Sequence</code> class in Keras and using <code>utils.dataset</code> in PyTorch.
  In Keras you would have something like</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.utils <span style="color:#f92672">import</span> Sequence
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pathlib <span style="color:#f92672">import</span> Path
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomGenerator</span>(Sequence):
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __init__(self, path):
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>path <span style="color:#f92672">=</span> Path(path)
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>filenames <span style="color:#f92672">=</span> list(self<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#34;**/*.npy&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __len__(self):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> len(self<span style="color:#f92672">.</span>filenames)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __getitem__(self, index):
</span></span><span style="display:flex;"><span>    fn <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>filenames[index]
</span></span><span style="display:flex;"><span>    vector <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>load(fn)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> vector</span></span></code></pre></div>
</div>
<p>And here is the same code in PyTorch.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.utils.data <span style="color:#f92672">import</span> Dataset
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> pathlib <span style="color:#f92672">import</span> Path
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomDataset</span>(Dataset):
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __init__(self, path):
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>path <span style="color:#f92672">=</span> Path(path)
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>filenames <span style="color:#f92672">=</span> list(self<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#34;**/*.npy&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __len__(self):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> len(self<span style="color:#f92672">.</span>filenames)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> __getitem__(self, index):
</span></span><span style="display:flex;"><span>    fn <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>filenames[index]
</span></span><span style="display:flex;"><span>    vector <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>from_numpy(np<span style="color:#f92672">.</span>load(fn))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> vector</span></span></code></pre></div>
</div>
</div>
</div>
<div id="outline-container-headline-2" class="outline-2">
<h2 id="headline-2">
Define and build models
</h2>
<div id="outline-text-headline-2" class="outline-text-2">
<p>In Keras, we can define and build a model at the same time. In the following example, we use the <code>Sequential</code> (<a href="https://keras.io/api/models/sequential/)">https://keras.io/api/models/sequential/)</a> to build an LSTM network with an embedding layer. and single neuron output.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.models <span style="color:#f92672">import</span> Sequential
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> LSTM, Dense, Embedding
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_model</span>(vocab_size<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>,
</span></span><span style="display:flex;"><span>             hidden_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span> model <span style="color:#f92672">=</span> Sequential()
</span></span><span style="display:flex;"><span> model<span style="color:#f92672">.</span>add(Embedding(vocab_size, embedding_dim))
</span></span><span style="display:flex;"><span> model<span style="color:#f92672">.</span>add(LSTM(hidden_size))
</span></span><span style="display:flex;"><span> model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sigmoid&#34;</span>))
</span></span><span style="display:flex;"><span> model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;adam&#34;</span>, loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;binary_crossentropy&#34;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;accuracy&#34;</span>])
</span></span><span style="display:flex;"><span> <span style="color:#66d9ef">return</span> model</span></span></code></pre></div>
</div>
<p>And here is the same architecture in PyTorch.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.nn.functional <span style="color:#f92672">import</span> softmax
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomModel</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span> <span style="color:#66d9ef">def</span> __init__(self, vocab_size<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
</span></span><span style="display:flex;"><span>              embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>,
</span></span><span style="display:flex;"><span>              hidden_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
</span></span><span style="display:flex;"><span>     super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>     self<span style="color:#f92672">.</span>encoder <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(vocab_size, embedding_dim)
</span></span><span style="display:flex;"><span>     self<span style="color:#f92672">.</span>lstm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LSTM(embedding_dim, hidden_size)
</span></span><span style="display:flex;"><span>     self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(hidden_size, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>self<span style="color:#f92672">.</span>activation <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sigmoid()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>     output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder(x)
</span></span><span style="display:flex;"><span>     output, _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lstm(output)
</span></span><span style="display:flex;"><span>     output <span style="color:#f92672">=</span> output[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#75715e"># Keep last output only</span>
</span></span><span style="display:flex;"><span>     output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>linear(output)
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>activation(output)
</span></span><span style="display:flex;"><span>     <span style="color:#66d9ef">return</span> output</span></span></code></pre></div>
</div>
<p>The <code>__init__</code> function instantiates the different modules of the network while the actual computation is decided in the <code>forward</code> function. Actually, we still need to &#34;compile&#34; the model like in the Keras example. However, as you will see in how models are trained, we define metrics, models and optimizers separately in PyTorch and call them when needed in the training loop. So we only need to define the same criterion for metric and the same optimizer as above.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>  <span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>  criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BCELoss()
</span></span><span style="display:flex;"><span>  optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>parameters())
</span></span><span style="display:flex;"><span>  model <span style="color:#f92672">=</span> CustomModel()</span></span></code></pre></div>
</div>
<p>In most cases, default parameters in Keras will match defaults in PyTorch, as it is the case for the Adam optimizer and the BCE (Binary Cross-Entropy) loss.</p>
<p>
   To summarize, we have this table of comparison of the two syntaxes.</p>
<table>
<thead>
<tr>
<th>Keras</th>
<th>Pytorch</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model.call</td>
<td>Module.forward</td>
</tr>
<tr>
<td>layers.Layer</td>
<td>nn.Module</td>
</tr>
<tr>
<td>layers.Dense</td>
<td>nn.Linear (without activation)</td>
</tr>
<tr>
<td>layers.LSTM(return_sequences=True)</td>
<td>nn.LSTM</td>
</tr>
<tr>
<td>utils.Sequence</td>
<td>utils.data.Dataset</td>
</tr>
<tr>
<td>activation=&#34;sigmoid&#34; parameter to layer object</td>
<td>nn.Sigmoid()</td>
</tr>
<tr>
<td>loss=&#34;binary-crossentropy&#34; parameter to model.compile</td>
<td>nn.BCELoss</td>
</tr>
<tr>
<td>optimizer=&#34;adam&#34; parameter to model.compile</td>
<td>torch.optim.Adam()</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-headline-3" class="outline-2">
<h2 id="headline-3">
Manipulate tensors
</h2>
<div id="outline-text-headline-3" class="outline-text-2">
<p>Both frameworks have their own specificities in syntax for manipulating tensors. Here we will compare PyTorch and Tensorflow.</p>
<div id="outline-container-headline-4" class="outline-3">
<h3 id="headline-4">
Shape of tensors
</h3>
<div id="outline-text-headline-4" class="outline-text-3">
<p>Pytorch has <code>.shape</code> and <code>.size</code> which are both equivalent to access the shape of tensors.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>print(t<span style="color:#f92672">.</span>shape, t<span style="color:#f92672">.</span>size())         <span style="color:#75715e"># Both equal to (4, 3)</span>
</span></span><span style="display:flex;"><span>t<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], t<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>)     <span style="color:#75715e"># Both equal to 3</span></span></span></code></pre></div>
</div>
<p>Tensorflow has only <code>.shape</code></p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>t <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">3</span>))
</span></span><span style="display:flex;"><span>print(t<span style="color:#f92672">.</span>shape)            <span style="color:#75715e"># .size is not available</span>
</span></span><span style="display:flex;"><span>print(t<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>])</span></span></code></pre></div>
</div>
</div>
</div>
<div id="outline-container-headline-5" class="outline-3">
<h3 id="headline-5">
Order of dimensions
</h3>
<div id="outline-text-headline-5" class="outline-text-3">
<p>Keras usually orders dimensions as <code>(batch_size, seq_len, input_dim)</code>, whereas Pytorch prefers to order them by default as <code>(seq_len, batch_size, input_dim)</code>. In PyTorch, recurrent networks like LSTM, GRU have a switch parameter <code>batch_first</code> which, if set to <code>True</code>, will expect inputs to be of shape <code>(seq_len, batch_size, input_dim)</code>. However modules like Transformer do not have such parameter. In this case, the input will have to be adapted. To do so, you can switch dimensions in Pytorch using <code>.transpose</code> method.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>Tensor(tensor_with_batch_first)
</span></span><span style="display:flex;"><span>data<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)            <span style="color:#75715e"># Switch first and second dimensions</span></span></span></code></pre></div>
</div>
<p>
       The order chosen by PyTorch is more natural from a parallel computing viewpoint. For example, a recurrent layer will be applied in parallel at each step of the sequence, to all batch, so we will iterate over the <code>seq_len</code> dimension which is first. The order preferred by Keras is more natural in terms of model architecture, since we would rather consider one input sequence to be fed to the model, then simply duplicate the operation for a batch.</p>
</div>
</div>
<div id="outline-container-headline-6" class="outline-3">
<h3 id="headline-6">
Initialize vectors
</h3>
<div id="outline-text-headline-6" class="outline-text-3">
<p>PyTorch has a syntax very similar to numpy.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>ones(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">1</span>)         <span style="color:#75715e"># Matrix of size (2, 4, 1) filled with 1. Same as torch.zeros</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>eye(<span style="color:#ae81ff">3</span>)                <span style="color:#75715e"># Identity matrix of size (3,3)</span></span></span></code></pre></div>
</div>
<p>Good news! All above methods are present and work the same in Tensorflow.
  In addition, we have <code>torch.full</code> which is the equivalent of <code>numpy.fill</code>, for filling a tensor with one value. Tensorflow has <code>tf.fill</code>.</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>full((<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>), fill_value<span style="color:#f92672">=</span><span style="color:#ae81ff">3.14</span>)  <span style="color:#75715e"># Fill a (2, 4) matrix with 3.14 value.</span>
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>fill((<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>), value<span style="color:#f92672">=</span><span style="color:#ae81ff">3.14</span>)</span></span></code></pre></div>
</div>
<p>Here is how to sample a matrix of random numbers</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>)            <span style="color:#75715e"># Sample from N(0, 1) a matrix of size (2, 3)</span>
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(shape<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>randint(low<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, high<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>))  <span style="color:#75715e"># Sample uniformely a (2, 5) matrix of integers within [10, 20[</span>
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(shape<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>], minval<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, maxval<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int64)</span></span></code></pre></div>
</div>
<p>
Reproducibility seed for the random number generator can be set with</p>
<div class="src src-python">
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>manual_seed(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>set_seed(<span style="color:#ae81ff">0</span>)</span></span></code></pre></div>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-headline-7" class="outline-2">
<h2 id="headline-7">
Conclusion
</h2>
<div id="outline-text-headline-7" class="outline-text-2">
<p>While Keras and Pytorch have very similar data loading logic, their syntax quite differs for the rest. PyTorch has a pythonic syntax while Keras is designed for writing short and concise programs, without taking too much time on expliciting building blocks. There are many more points of comparison but I hope this article gives some insights on both frameworks. For the sake of completeness, I share some resources I found covering a comparison between Keras and PyTorch.</p>
<dl>
<dt>
Comparison and speed benchmark of Keras and PyTorch with a ConvNet architecture
</dt>
<dd><a href="https://deepsense.ai/keras-or-pytorch/">https://deepsense.ai/keras-or-pytorch/</a></dd>
<dt>
A multi-GPU framework comparison
</dt>
<dd><a href="https://medium.com/@iliakarmanov/multi-gpu-rosetta-stone-d4fa96162986">https://medium.com/@iliakarmanov/multi-gpu-rosetta-stone-d4fa96162986</a></dd>
<dt>
A rosetta stone repository between deep learning frameworks
</dt>
<dd><a href="https://github.com/ilkarman/DeepLearningFrameworks/">https://github.com/ilkarman/DeepLearningFrameworks/</a></dd>
<dt>
Comparison of Keras and PyTorch on image classification
</dt>
<dd><a href="https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/">https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/</a></dd>
</dl>
<p>
   In the next article, I will present a practical implementation for sentiment classification with comparison in both Keras and PyTorch.</p>
</div>
</div>

  </div>
  <footer>
    <ul class="stats">
  
    
    
      <li class="categories">
        <ul>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/categories/machine-learning">Machine Learning</a></li>
          
        </ul>
      </li>
    
  
  
    
    
      <li class="tags">
        <ul>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/machine-learning">machine-learning</a></li>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/pytorch">pytorch</a></li>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/keras">keras</a></li>
          
        </ul>
      </li>
    
  
</ul>

  </footer>
</article>

    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "adamoudad-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>




<div class="pagination">
  
    <a href="/posts/lock_pattern/" class="button"><div class="previous"><div>How many patterns are there to lock your android smartphone?</div></div></a>
  
  
    <a href="/posts/keras_torch_comparison/sentiment_classification/" class="button"><div class="next"><div>Comparing Keras and PyTorch on sentiment classification</div></div></a>
  
</div>


      </main>
      <section id="site-sidebar">
  
    <section id="recent-posts">
      <header>
        <h1>Recent posts</h1>
      </header>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/ecg-anomaly-detection/">Time-series anomaly detection with autoencoder</a></h1>
          <time class="published" datetime="">July 23, 2023</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/emacs/remote-command-ssh/">Run a command on a remote server with Emacs.</a></h1>
          <time class="published" datetime="">December 22, 2022</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/python-statements/">These Python keywords will simplify your code</a></h1>
          <time class="published" datetime="">October 16, 2022</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/pdfpc/">Keynote presentation on Linux</a></h1>
          <time class="published" datetime="">October 15, 2022</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/swap_control_caps/">Swap Control and Caps keys to relieve stress on the pinky</a></h1>
          <time class="published" datetime="">April 5, 2021</time>
        </header>
      </article>
      
      
        <a href="/posts/" class="button">See more</a>
      
    </section>
  

  
    
      <section id="categories">
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
            
          
          
          <li>
            
              <a href="/categories/machine-learning/">machine-learning<span class="count">10</span></a>
            
          
          <li>
            
              <a href="/categories/programming/">programming<span class="count">6</span></a>
            
          
          <li>
            
              <a href="/categories/linux/">linux<span class="count">3</span></a>
            
          
          <li>
            
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">3</span></a>
            
          
          <li>
            
              <a href="/categories/python/">python<span class="count">3</span></a>
            
          
          <li>
            
              <a href="/categories/emacs/">emacs<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/japanese/">japanese<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/security/">security<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/web/">web<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/computer/">computer<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/linguistic/">linguistic<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/random/">random<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/tools/">tools<span class="count">1</span></a>
            
          
          </li>
        </ul>
      </section>
    
  

  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>This website is a weblog were I write about computer science, machine learning, language learning.</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/adamoudad" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/7013114/adam-oudad" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@adam.oudad" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//linkedin.com/in/adamoudad" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>















<li><a href="//twitter.com/OudadAdam" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>







<li><a href="//researchgate.net/profile/Adam_Oudad" target="_blank" rel="noopener" title="Research Gate"><i class="ai ai-researchgate"></i></a></li>





      </ul>
  
  <p class="copyright">
    
      &copy; 2023
      
        (Machine) Learning log.
      
    . <br>
    Theme: <a href='https://github.com/pacollins/hugo-future-imperfect-slim' target='_blank' rel='noopener'>Hugo Future Imperfect Slim</a><br>A <a href='https://html5up.net/future-imperfect' target='_blank' rel='noopener'>HTML5 UP port</a> | Powered by <a href='https://gohugo.io/' title='0.99.1' target='_blank' rel='noopener'>Hugo</a>
  </p>
</footer>
<a id="back-to-top" href="#" class="fas fa-arrow-up fa-2x"></a>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css" integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js" integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js" integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>


      <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="/js/bundle.min.d0b3e0b5f2cfc7467ead7d316ecb9dea4d29ef3c23ad300df9d7017ff98b2331.js" integrity="sha256-0LPgtfLPx0Z&#43;rX0xbsud6k0p7zwjrTAN&#43;dcBf/mLIzE="></script>
    <script src="/js/add-on.js"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-ZKMEYDZ08Y"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-ZKMEYDZ08Y', { 'anonymize_ip': false });
}
</script>

    </div>
  </body>
</html>
