<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<title>Comparison of Keras and PyTorch syntaxes - Adam Oudad</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="monetization" content="$ilp.uphold.com/iN8Xkq2iHNHB">


<meta name="generator" content="Hugo 0.80.0" /><meta itemprop="name" content="Comparison of Keras and PyTorch syntaxes">
<meta itemprop="description" content="Keras and PyTorch are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast. There are similar abstraction layers developped on top of PyTorch, such as PyTorch Ignite or PyTorch lightning. They are not yet as mature as Keras, but are worth the try!
 I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks.">
<meta itemprop="datePublished" content="2021-03-02T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-03-02T00:00:00+00:00" />
<meta itemprop="wordCount" content="1089">



<meta itemprop="keywords" content="machine-learning,pytorch,keras," />
<meta property="og:title" content="Comparison of Keras and PyTorch syntaxes" />
<meta property="og:description" content="Keras and PyTorch are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast. There are similar abstraction layers developped on top of PyTorch, such as PyTorch Ignite or PyTorch lightning. They are not yet as mature as Keras, but are worth the try!
 I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adamoudad.github.io/posts/keras_pytorch_comparison/" />
<meta property="article:published_time" content="2021-03-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-03-02T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Comparison of Keras and PyTorch syntaxes"/>
<meta name="twitter:description" content="Keras and PyTorch are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast. There are similar abstraction layers developped on top of PyTorch, such as PyTorch Ignite or PyTorch lightning. They are not yet as mature as Keras, but are worth the try!
 I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks."/>
<meta name="twitter:site" content="@OudadAdam"/>
<link rel="stylesheet" href="/css/bundle.min.a86839252b4aa4853111ceba45af5da1d6c3dc66a6a3b6854750bb2df61dfe37.css" integrity="sha256-qGg5JStKpIUxEc66Ra9dodbD3Gamo7aFR1C7LfYd/jc=">
        <link rel="stylesheet" href="/css/add-on.css">
</head>

  <body>
    
<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/">
        
          
            posts
          
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu">
      
        
          
          
            <a href="/" class="link"><i class='fa fa-home'></i> Home</a>
          
        
      
        
          
          
            <a href="/about/" class="link"><i class='far fa-id-card'></i> About</a>
          
        
      
        
          
          
            <a href="/posts/" class="link"><i class='far fa-newspaper'></i> Posts</a>
          
        
      
        
          
          
            <a href="/categories/" class="link"><i class='fas fa-sitemap'></i> Categories</a>
          
        
      
      <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      

    </menu>
    

    <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="lang-menu" class="flyout-menu">
  <a href="#" lang="en" class="link active">English (en)</a>
  
    
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes&amp;url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_pytorch_comparison%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_pytorch_comparison%2f&amp;title=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro" >
  <a href="/"><img src="/avatar.png" class="circle" width="150" alt="Adam Oudad" /></a>
  <header>
    <h1>Adam Oudad</h1>
  </header>
  <main>
    <p>(Machine) Learning log.</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/adamoudad" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/7013114/adam-oudad" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@adam.oudad" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//linkedin.com/in/adam-oudad-9436b866" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>















<li><a href="//twitter.com/OudadAdam" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>







<li><a href="//researchgate.net/profile/Adam_Oudad" target="_blank" rel="noopener" title="Research Gate"><i class="ai ai-researchgate"></i></a></li>





      </ul>
    </footer>
  
</section>

      <main id="site-main">
        <article class="post">
  <header>
  <div class="title">
    
        <h2><a href="/posts/keras_pytorch_comparison/">Comparison of Keras and PyTorch syntaxes</a></h2>
    
    
</div>
  <div class="meta">
    <time class="published" datetime="2021-03-02 00:00:00 &#43;0000 UTC">
      March 2, 2021
    </time>
    <span class="author"></span>
    
      <p>6 minutes read</p>
    
  </div>
</header>

  <section id="socnet-share">
    




  
    
    <a href="//twitter.com/share?text=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes&amp;url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_pytorch_comparison%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fadamoudad.github.io%2fposts%2fkeras_pytorch_comparison%2f&amp;title=Comparison%20of%20Keras%20and%20PyTorch%20syntaxes" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  


  </section>
  

  <div class="content">
    
<p>
 <a href="https://keras.io/">Keras</a> and <a href="pytorch.org/">PyTorch</a> are popular frameworks for building programs with deep learning. The former, Keras, is more precisely an abstraction layer for Tensorflow and offers the capability to prototype models fast.
 There are similar abstraction layers developped on top of <a href="https://pytorch.org/">PyTorch</a>, such as <a href="https://pytorch.org/ignite/">PyTorch Ignite</a> or <a href="https://github.com/PyTorchLightning/pytorch-lightning">PyTorch lightning</a>. They are not yet as mature as Keras, but are worth the try!</p>
<p>
 I found few resources or articles comparing codes in both Keras and PyTorch and I will show such example in this article, to help understand the key differences in terms of syntax and naming between frameworks. To have a comparison on a concrete example, I implemented, using both frameworks, the same sentiment classifier architecture and trained it on IMDB dataset.
 This article is the first of a series, in which we will compare the syntaxes. I will publish later this month another article where I compare Keras and PyTorch in a practical experiment on sentiment classification.</p>
<div id="outline-container-headline-1" class="outline-2">
<h2 id="headline-1">
Prepare the data
</h2>
<div id="outline-text-headline-1" class="outline-text-2">
<p>The first comparison is on how data is loaded and prepared. Loading data can be achieved in a very similar fashion between both frameworks,  using <code>utils.Sequence</code> class in Keras and using <code>utils.dataset</code> in PyTorch.
  In Keras you would have something like</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> tensorflow.keras.utils <span style="color:#f92672">import</span> Sequence
<span style="color:#f92672">from</span> pathlib <span style="color:#f92672">import</span> Path
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">PianorollGenerator</span>(Sequence):
<span style="color:#66d9ef">def</span> __init__(self, path):
    self<span style="color:#f92672">.</span>path <span style="color:#f92672">=</span> Path(path)
    self<span style="color:#f92672">.</span>filenames <span style="color:#f92672">=</span> list(self<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#34;**/*.mid&#34;</span>))

<span style="color:#66d9ef">def</span> __len__(self):
    <span style="color:#66d9ef">return</span> len(self<span style="color:#f92672">.</span>filenames)

<span style="color:#66d9ef">def</span> __getitem__(self, index):
    fn <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>filenames[index]
    vector <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>load(fn)
    <span style="color:#66d9ef">return</span> vector</code></pre></div>
</div>
<p>And here is the same code in PyTorch.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> torch.utils.data <span style="color:#f92672">import</span> Dataset
<span style="color:#f92672">from</span> pathlib <span style="color:#f92672">import</span> Path
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomDataset</span>(Dataset):
<span style="color:#66d9ef">def</span> __init__(self, path):
    self<span style="color:#f92672">.</span>path <span style="color:#f92672">=</span> Path(path)
    self<span style="color:#f92672">.</span>filenames <span style="color:#f92672">=</span> list(self<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>glob(<span style="color:#e6db74">&#34;**/*.mid&#34;</span>))

<span style="color:#66d9ef">def</span> __len__(self):
    <span style="color:#66d9ef">return</span> len(self<span style="color:#f92672">.</span>filenames)

<span style="color:#66d9ef">def</span> __getitem__(self, index):
    fn <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>filenames[index]
    vector <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(fn)
    <span style="color:#66d9ef">return</span> vector</code></pre></div>
</div>
</div>
</div>
<div id="outline-container-headline-2" class="outline-2">
<h2 id="headline-2">
Define and build models
</h2>
<div id="outline-text-headline-2" class="outline-text-2">
<p>In Keras, we can define and build a model at the same time. In the following example, we use the <code>Sequential</code> (<a href="https://keras.io/api/models/sequential/)">https://keras.io/api/models/sequential/)</a> to build an LSTM network with an embedding layer. and single neuron output.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> tensorflow.keras.models <span style="color:#f92672">import</span> Sequential
<span style="color:#f92672">from</span> tensorflow.keras.layers <span style="color:#f92672">import</span> LSTM, Dense, Embedding
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">build_model</span>(vocab_size<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>,
             hidden_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
 model <span style="color:#f92672">=</span> Sequential()
 model<span style="color:#f92672">.</span>add(Embedding(vocab_size, embedding_dim))
 model<span style="color:#f92672">.</span>add(LSTM(hidden_size))
 model<span style="color:#f92672">.</span>add(Dense(<span style="color:#ae81ff">1</span>, activation<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;sigmoid&#34;</span>))
 model<span style="color:#f92672">.</span>compile(optimizer<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;adam&#34;</span>, loss<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;binary_crossentropy&#34;</span>, metrics<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;accuracy&#34;</span>])
 <span style="color:#66d9ef">return</span> model</code></pre></div>
</div>
<p>And here is the same architecture in PyTorch.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
<span style="color:#f92672">from</span> torch.nn.functional <span style="color:#f92672">import</span> softmax
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomModel</span>(nn<span style="color:#f92672">.</span>Module):
 <span style="color:#66d9ef">def</span> __init__(self, vocab_size<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>,
              embedding_dim<span style="color:#f92672">=</span><span style="color:#ae81ff">16</span>,
              hidden_size<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>):
     super()<span style="color:#f92672">.</span>__init__()
     self<span style="color:#f92672">.</span>encoder <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(vocab_size, embedding_dim)
     self<span style="color:#f92672">.</span>lstm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LSTM(embedding_dim, hidden_size)
     self<span style="color:#f92672">.</span>linear <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(hidden_size, <span style="color:#ae81ff">1</span>)
self<span style="color:#f92672">.</span>activation <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sigmoid()

 <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
     output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>encoder(x)
     output, _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>lstm(output)
     output <span style="color:#f92672">=</span> output[<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#75715e"># Keep last output only</span>
     output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>linear(output)
output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>activation(output)
     <span style="color:#66d9ef">return</span> output</code></pre></div>
</div>
<p>The <code>__init__</code> function instantiates the different modules of the network while the actual computation is decided in the <code>forward</code> function. Actually, we still need to &#34;compile&#34; the model like in the Keras example. However, as you will see in how models are trained, we define metrics, models and optimizers separately in PyTorch and call them when needed in the training loop. So we only need to define the same criterion for metric and the same optimizer as above.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">  <span style="color:#f92672">import</span> torch
  criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BCELoss()
  optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>parameters())</code></pre></div>
</div>
<p>In most cases, default parameters in Keras will match defaults in PyTorch, as it is the case for the Adam optimizer and the BCE (Binary Cross-Entropy) loss.</p>
<p>
   To summarize, we have this table of comparison of the two syntaxes.</p>
<table>
<thead>
<tr>
<th>Keras</th>
<th>Pytorch</th>
</tr>
</thead>
<tbody>
<tr>
<td>Model.call</td>
<td>Module.forward</td>
</tr>
<tr>
<td>layers.Layer</td>
<td>nn.Module</td>
</tr>
<tr>
<td>layers.Dense</td>
<td>nn.Linear (without activation)</td>
</tr>
<tr>
<td>layers.LSTM(return_sequences=True)</td>
<td>nn.LSTM</td>
</tr>
<tr>
<td>utils.Sequence</td>
<td>utils.data.Dataset</td>
</tr>
<tr>
<td>activation=&#34;sigmoid&#34; parameter to layer object</td>
<td>nn.Sigmoid()</td>
</tr>
<tr>
<td>loss=&#34;binary-crossentropy&#34; parameter to model.compile</td>
<td>nn.BCELoss</td>
</tr>
<tr>
<td>optimizer=&#34;adam&#34; parameter to model.compile</td>
<td>torch.optim.Adam()</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-headline-3" class="outline-2">
<h2 id="headline-3">
Work with tensors
</h2>
<div id="outline-text-headline-3" class="outline-text-2">
<p>Both frameworks have their own specificities in syntax for manipulating tensors. Here we will compare PyTorch and Tensorflow.</p>
<div id="outline-container-headline-4" class="outline-3">
<h3 id="headline-4">
Shape of tensors
</h3>
<div id="outline-text-headline-4" class="outline-text-3">
<p>Pytorch has .shape and .size which are both equivalent to access the shape of tensors.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">3</span>))
<span style="color:#66d9ef">print</span>(t<span style="color:#f92672">.</span>shape, t<span style="color:#f92672">.</span>size())         <span style="color:#75715e"># Both equal to (4, 3)</span>
t<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>], t<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">1</span>)     <span style="color:#75715e"># Both equal to 3</span></code></pre></div>
</div>
<p>Tensorflow works like this.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">t <span style="color:#f92672">=</span> tf<span style="color:#f92672">.</span>zeros((<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">3</span>))
<span style="color:#66d9ef">print</span>(t<span style="color:#f92672">.</span>shape)            <span style="color:#75715e"># .size is not available</span>
<span style="color:#66d9ef">print</span>(t<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>])</code></pre></div>
</div>
</div>
</div>
<div id="outline-container-headline-5" class="outline-3">
<h3 id="headline-5">
Order of dimensions in Pytorch
</h3>
<div id="outline-text-headline-5" class="outline-text-3">
<p>Keras usually orders dimensions as <code>(batch_size, seq_len, input_dim)</code>, whereas Pytorch prefers to order them by default as <code>(seq_len, batch_size, input_dim)</code>. In PyTorch, recurrent networks like LSTM, GRU have a switch parameter <code>batch_first</code> which, if set to <code>True</code>, will expect inputs to be of shape <code>(seq_len, batch_size, input_dim)</code>. However modules like Transformer do not have such parameter. In this case, the input will have to be adapted. To do so, you can switch dimensions in Pytorch using <code>.transpose</code> method.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">data <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>Tensor(tensor_with_batch_first)
data<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)            <span style="color:#75715e"># Switch first and second dimensions</span></code></pre></div>
</div>
<p>
       The order chosen by PyTorch is more natural from a parallel computing viewpoint. For example, a recurrent layer will be applied in parallel at each step of the sequence, to all batch, so we will iterate over the <code>seq_len</code> dimension which is first. The order preferred by Keras is more natural in terms of model architecture, since we would rather consider one input sequence to be fed to the model, then simply duplicate the operation for a batch.</p>
</div>
</div>
<div id="outline-container-headline-6" class="outline-3">
<h3 id="headline-6">
Initialize vectors in PyTorch
</h3>
<div id="outline-text-headline-6" class="outline-text-3">
<p>PyTorch has a syntax very similar to numpy.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">torch<span style="color:#f92672">.</span>ones(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">1</span>)         <span style="color:#75715e"># Matrix of size (2, 4, 1) filled with 1. Same with torch.zeros</span>
torch<span style="color:#f92672">.</span>eye(<span style="color:#ae81ff">3</span>)                <span style="color:#75715e"># Identity matrix of size (3,3)</span></code></pre></div>
</div>
<p>Good news! All above methods are present and work the same in Tensorflow.
  In addition, we have <code>torch.full</code> which is the equivalent of <code>numpy.fill</code>, for filling a tensor with one value. Tensorflow has <code>tf.fill</code>.</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">torch<span style="color:#f92672">.</span>full((<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>), fill_value<span style="color:#f92672">=</span><span style="color:#ae81ff">3.14</span>)  <span style="color:#75715e"># Fill a (2, 4) matrix with 3.14 value.</span>
tf<span style="color:#f92672">.</span>fill((<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>), value<span style="color:#f92672">=</span><span style="color:#ae81ff">3.14</span>)</code></pre></div>
</div>
<p>Here is how to sample a matrix of random numbers</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>)            <span style="color:#75715e"># Sample from N(0, 1) a matrix of size (2, 3)</span>
tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(shape<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>])

torch<span style="color:#f92672">.</span>randint(low<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, high<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>))  <span style="color:#75715e"># Sample uniformely a (2, 5) matrix of integers within [10, 20[</span>
tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(shape<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>], minval<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, maxval<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, dtype<span style="color:#f92672">=</span>tf<span style="color:#f92672">.</span>int64)</code></pre></div>
</div>
<p>
Reproducibility seed for the random number generator can be set with</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">torch<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>manual_seed(<span style="color:#ae81ff">0</span>)
tf<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>set_seed(<span style="color:#ae81ff">0</span>)</code></pre></div>
</div>
</div>
</div>
</div>
</div>
<div id="outline-container-headline-7" class="outline-2">
<h2 id="headline-7">
Conclusion
</h2>
<div id="outline-text-headline-7" class="outline-text-2">
<p>While Keras and Pytorch have very similar data loading logic, there syntax is quite different for the rest. PyTorch has a pythonic and elegant syntax while Keras is designed for writing short and concise programs, without taking too much time on rewriting the building blocks. There are many more points of comparison but I hope this article gives some insights on both frameworks. For the sake of completeness, I share some resources I found covering a comparison between Keras and PyTorch.</p>
<dl>
<dt>
Comparison and speed benchmark of Keras and PyTorch with a ConvNet architecture
</dt>
<dd>
<p><a href="https://deepsense.ai/keras-or-pytorch/">https://deepsense.ai/keras-or-pytorch/</a></p>
</dd>
<dt>
A multi-GPU framework comparison
</dt>
<dd>
<p><a href="https://medium.com/@iliakarmanov/multi-gpu-rosetta-stone-d4fa96162986">https://medium.com/@iliakarmanov/multi-gpu-rosetta-stone-d4fa96162986</a></p>
</dd>
<dt>
A rosetta stone repository between deep learning frameworks
</dt>
<dd>
<p><a href="https://github.com/ilkarman/DeepLearningFrameworks/">https://github.com/ilkarman/DeepLearningFrameworks/</a></p>
</dd>
<dt>
Comparison of Keras and PyTorch on image classification
</dt>
<dd>
<p><a href="https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/">https://deepsense.ai/keras-vs-pytorch-avp-transfer-learning/</a></p>
</dd>
</dl>
<p>
   In the next article, I will present a practical implementation for sentiment classification with comparison in both Keras and PyTorch.</p>
</div>
</div>

  </div>
  <footer>
    <ul class="stats">
  
    
    
      <li class="categories">
        <ul>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/categories/machine-learning">Machine Learning</a></li>
          
        </ul>
      </li>
    
  
  
    
    
      <li class="tags">
        <ul>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/machine-learning">machine-learning</a></li>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/pytorch">pytorch</a></li>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/keras">keras</a></li>
          
        </ul>
      </li>
    
  
</ul>

  </footer>
</article>

    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "adamoudad-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>




<div class="pagination">
  
    <a href="/posts/keras_torch_comparison/" class="button"><div class="previous"><div>Guide to swtich between Keras and PyTorch</div></div></a>
  
  
</div>


      </main>
      <section id="site-sidebar">
  
    <section id="recent-posts">
      <header>
        <h1>Recent posts</h1>
      </header>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/keras_pytorch_comparison/">Comparison of Keras and PyTorch syntaxes</a></h1>
          <time class="published" datetime="">March 2, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/keras_torch_comparison/">Guide to swtich between Keras and PyTorch</a></h1>
          <time class="published" datetime="">January 30, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/lock_pattern/">How many patterns are there to lock your android smartphone?</a></h1>
          <time class="published" datetime="">January 16, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/pierre-corneille-bot/">Ask this bot to solve your dilemmas</a></h1>
          <time class="published" datetime="">November 18, 2020</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/progress_bar_with_tqdm/">Training models with a progress bar</a></h1>
          <time class="published" datetime="">October 12, 2020</time>
        </header>
      </article>
      
      
        <a href="/posts/" class="button">See more</a>
      
    </section>
  

  
    
      <section id="categories">
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
            
          
          
          <li>
            
              <a href="/categories/machine-learning/">machine-learning<span class="count">9</span></a>
            
          
          <li>
            
              <a href="/categories/programming/">programming<span class="count">6</span></a>
            
          
          <li>
            
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">3</span></a>
            
          
          <li>
            
              <a href="/categories/japanese/">japanese<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/linux/">linux<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/python/">python<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/security/">security<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/web/">web<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/emacs/">emacs<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/linguistic/">linguistic<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/random/">random<span class="count">1</span></a>
            
          
          </li>
        </ul>
      </section>
    
  

  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>This website is a weblog were I write about computer science, machine learning, language learning.</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/adamoudad" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/7013114/adam-oudad" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@adam.oudad" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//linkedin.com/in/adam-oudad-9436b866" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>















<li><a href="//twitter.com/OudadAdam" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>







<li><a href="//researchgate.net/profile/Adam_Oudad" target="_blank" rel="noopener" title="Research Gate"><i class="ai ai-researchgate"></i></a></li>





      </ul>
  
  <p class="copyright">
    
      &copy; 2021
      
        Adam Oudad
      
    . <br>
    Theme: <a href='https://github.com/pacollins/hugo-future-imperfect-slim' target='_blank' rel='noopener'>Hugo Future Imperfect Slim</a><br>A <a href='https://html5up.net/future-imperfect' target='_blank' rel='noopener'>HTML5 UP port</a> | Powered by <a href='https://gohugo.io/' title='0.80.0' target='_blank' rel='noopener'>Hugo</a>
  </p>
</footer>
<a id="back-to-top" href="#" class="fas fa-arrow-up fa-2x"></a>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css" integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js" integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js" integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>


      <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="/js/bundle.min.e0c399b948d3cf5c3a5e3badb94023d0b064a19ac39fd8cd79fb9f57fa4d1091.js" integrity="sha256-4MOZuUjTz1w6XjutuUAj0LBkoZrDn9jNefufV/pNEJE="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-150494000-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
</html>
