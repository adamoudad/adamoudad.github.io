<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<title>Word embeddings with sound - (Machine) Learning log.</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="monetization" content="$ilp.uphold.com/iN8Xkq2iHNHB">


<meta name="generator" content="Hugo 0.99.1" /><meta itemprop="name" content="Word embeddings with sound">
<meta itemprop="description" content="I came across this article called Sound-Word2Vec:Learning Word Representations Grounded in Sounds1, which caught my attention as it aims at creating word embeddings in an original way, using voiced sounds of words.
What is embedding  Embedding in Machine Learning refers to a method for capturing the information of an input data into a dense representation. This way, we obtain an embedding space, which should have interesting properties like being friendly to vector arithmetics, which is not the case of original raw data."><meta itemprop="datePublished" content="2019-10-21T03:49:04+09:00" />
<meta itemprop="dateModified" content="2019-10-21T03:49:04+09:00" />
<meta itemprop="wordCount" content="511">
<meta itemprop="keywords" content="nlp,embedding," /><meta property="og:title" content="Word embeddings with sound" />
<meta property="og:description" content="I came across this article called Sound-Word2Vec:Learning Word Representations Grounded in Sounds1, which caught my attention as it aims at creating word embeddings in an original way, using voiced sounds of words.
What is embedding  Embedding in Machine Learning refers to a method for capturing the information of an input data into a dense representation. This way, we obtain an embedding space, which should have interesting properties like being friendly to vector arithmetics, which is not the case of original raw data." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://adamoudad.github.io/posts/sound-word2vec/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-10-21T03:49:04+09:00" />
<meta property="article:modified_time" content="2019-10-21T03:49:04+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Word embeddings with sound"/>
<meta name="twitter:description" content="I came across this article called Sound-Word2Vec:Learning Word Representations Grounded in Sounds1, which caught my attention as it aims at creating word embeddings in an original way, using voiced sounds of words.
What is embedding  Embedding in Machine Learning refers to a method for capturing the information of an input data into a dense representation. This way, we obtain an embedding space, which should have interesting properties like being friendly to vector arithmetics, which is not the case of original raw data."/>
<meta name="twitter:site" content="@OudadAdam"/>
<link rel="stylesheet" href="/css/bundle.min.262e62e9c1615dd1ac95d339cfc4ca2167aee72b71d853838920a22e7088b06b.css" integrity="sha256-Ji5i6cFhXdGsldM5z8TKIWeu5ytx2FODiSCiLnCIsGs=">
        <link rel="stylesheet" href="/css/add-on.css">
</head>

  <body>
    
<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/">
        
          
            posts
          
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu">
      
        
          
          
            <a href="/" class="link"><i class='fa fa-home'></i> Home</a>
          
        
      
        
          
          
            <a href="/about/" class="link"><i class='far fa-id-card'></i> About</a>
          
        
      
        
          
          
            <a href="/posts/" class="link"><i class='far fa-newspaper'></i> Posts</a>
          
        
      
        
          
          
            <a href="/categories/" class="link"><i class='fas fa-sitemap'></i> Categories</a>
          
        
      
      <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      

    </menu>
    

    <a href="#share-menu" class="share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    <a href="#lang-menu" class="lang-toggle" lang="en">en</a>
    <a href="#site-nav" class="nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="lang-menu" class="flyout-menu">
  <a href="#" lang="en" class="link active">English (en)</a>
  
    
      
    
      
        <a href="/fr" lang="fr" class="no-lang link">Français (fr)</a>
      
    
  
</menu>

  
    <menu id="share-menu" class="flyout-menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Word%20embeddings%20with%20sound&amp;url=https%3a%2f%2fadamoudad.github.io%2fposts%2fsound-word2vec%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fadamoudad.github.io%2fposts%2fsound-word2vec%2f&amp;title=Word%20embeddings%20with%20sound" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro" >
  <a href="/"><img src="/avatar.png" class="circle" width="150" alt="Adam Oudad" /></a>
  <header>
    <h1>Adam Oudad</h1>
  </header>
  <main>
    <p>(Machine) Learning log.</p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        

        <li><a href="//github.com/adamoudad" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/7013114/adam-oudad" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@adam.oudad" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//linkedin.com/in/adamoudad" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>















<li><a href="//twitter.com/OudadAdam" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>







<li><a href="//researchgate.net/profile/Adam_Oudad" target="_blank" rel="noopener" title="Research Gate"><i class="ai ai-researchgate"></i></a></li>





      </ul>
    </footer>
  
</section>

      <main id="site-main">
        <article class="post">
  <header>
  <div class="title">
    
        <h2><a href="/posts/sound-word2vec/">Word embeddings with sound</a></h2>
    
    
</div>
  <div class="meta">
    <time class="published" datetime="2019-10-21 03:49:04 &#43;0900 JST">
      October 21, 2019
    </time>
    <span class="author"></span>
    
      <p>3 minutes read</p>
    
  </div>
</header>

  <section id="socnet-share">
    




  
    
    <a href="//twitter.com/share?text=Word%20embeddings%20with%20sound&amp;url=https%3a%2f%2fadamoudad.github.io%2fposts%2fsound-word2vec%2f" target="_blank" rel="noopener" class="share-btn twitter">
        <i class="fab fa-twitter"></i><p>&nbsp;Twitter</p>
      </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fadamoudad.github.io%2fposts%2fsound-word2vec%2f&amp;title=Word%20embeddings%20with%20sound" target="_blank" rel="noopener" class="share-btn linkedin">
            <i class="fab fa-linkedin"></i><p>&nbsp;LinkedIn</p>
          </a>
  


  </section>
  

  <div class="content">
    
<p>
  I came across this article called <a href="https://www.aclweb.org/anthology/D17-1096.pdf">Sound-Word2Vec:Learning Word Representations Grounded in Sounds</a><sup class="footnote-reference"><a id="footnote-reference-1" href="#footnote-1">1</a></sup>, which caught my attention as it aims at creating word embeddings in an original way, using voiced sounds of words.</p>
<div id="outline-container-headline-1" class="outline-2">
<h2 id="headline-1">
What is embedding
</h2>
<div id="outline-text-headline-1" class="outline-text-2">
<p>Embedding in Machine Learning refers to a method for capturing the information of an input data into a dense representation. This way, we obtain an embedding space, which should have interesting properties like being friendly to vector arithmetics, which is not the case of original raw data.</p>
<p>
  For example, one-hot encoding is somewhat a poor embedding method, as it encodes data into a sparse vector space, and interpolation will not work as expected. What I mean by &#34;as expected&#34; is, we would prefer our embedding space to relate distances between vectors to something interpretable, such as semantics (synonyms, antonyms, etc). For this, Word2Vec performs quite well.</p>
</div>
</div>
<div id="outline-container-headline-2" class="outline-2">
<h2 id="headline-2">
What is the point of using sound ?
</h2>
<div id="outline-text-headline-2" class="outline-text-2">
<p>Human language can be written and spoken. Embeddings grounded in sounds capture dependancies between words and onomatopeia.
  It is important to give machines an insight on sound dependancies of words, therefore bridging the gap between natural language and speech.</p>
<p>
  In the research paper, sounds are clustered using various audio features, with K-means clustering. This is then considered as the target of the learning phase for the model.</p>
</div>
</div>
<div id="outline-container-headline-3" class="outline-2">
<h2 id="headline-3">
Sound-Word2Vec model
</h2>
<div id="outline-text-headline-3" class="outline-text-2">
<p>The model is similar to Word2Vec. A hidden layer is a fully-connected layer with softmax activation.
  <figure><img src="figure-1.png" width="100%"/>
</figure>

  The task is simply to predict the sound cluster a given input word falls into. A Word2Vec pretrained model is used to take advantage of semantic information already contained in such embeddings. This is relatable to the technique of Transfer Learning, where the model is adapted to a new context, for performing better at sound-related tasks. Indeed, the model is therefore tested on three sound-related tasks:</p>
<dl>
<dt>
Text-based sound retrieval
</dt>
<dd>given a textual description, find a corresponding sound in the database</dd>
<dt>
Foley sound discovery
</dt>
<dd>Given an outline of describing the technique for producing a sound, find relevant words suitable for producing the same sound</dd>
<dt>
Aurally relevant relatedness
</dt>
<dd></dd>
</dl>
</div>
</div>
<div id="outline-container-headline-4" class="outline-2">
<h2 id="headline-4">
Sound data
</h2>
<div id="outline-text-headline-4" class="outline-text-2">
<p>Sound data was retrieved from <a href="http://www.freesound.org/">freesound.org</a>, a website collecting sounds uploaded by users. This represents a huge database of various tagged sounds with descriptions.</p>
</div>
</div>
<div id="outline-container-headline-5" class="outline-2">
<h2 id="headline-5">
Nearest neighbors are sound-related
</h2>
<div id="outline-text-headline-5" class="outline-text-2">
<p>The following table from the original paper show how such embeddings differ from Word2Vec&#39;s embeddings, which are semantically related. <em>apple</em> is associated with <em>bite</em>, <em>chew</em>, <em>munch</em>, instead of <em>fruit</em>, <em>pears</em>.
  <figure><img src="table-3.png" width="100%"/>
</figure>
</p>
<p>
  Recall results on Text-based sound retrieval task are registered on the following table.
  <figure><img src="table-1.png" width="100%"/>
</figure>
</p>
</div>
</div>
<div id="outline-container-headline-6" class="outline-2">
<h2 id="headline-6">
Final words
</h2>
<div id="outline-text-headline-6" class="outline-text-2">
<p>Embeddings are crucial in connectionist view of Machine Learning, as they present input information in a suitable form for subsequent task to perform. I can think of such embeddings being used for lyrics generation, speech recognition, or sentiment analysis. The goal of course is to encapsulate as much relevant information as you can in your embedding, so I believe bridging two fields like sound and natural language is the way to go if we want to obtain rich embeddings.</p>
</div>
</div>
<div id="outline-container-headline-7" class="outline-2">
<h2 id="headline-7">
Footnotes
</h2>
</div>
<div class="footnotes">
<hr class="footnotes-separatator">
<div class="footnote-definitions">
<div class="footnote-definition">
<sup id="footnote-1"><a href="#footnote-reference-1">1</a></sup>
<div class="footnote-body">
<p>Sound-Word2Vec:Learning Word Representations Grounded in Sounds, A. Vijayakumar, R Vedantam, D. Parikh, EMNLP conference 2017.</p>
</div>
</div>
</div>
</div>

  </div>
  <footer>
    <ul class="stats">
  
    
    
      <li class="categories">
        <ul>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/categories/natural-language-processing">Natural Language Processing</a></li>
          
        </ul>
      </li>
    
  
  
    
    
      <li class="tags">
        <ul>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/nlp">nlp</a></li>
          
            
            <li><a class="article-category-link" href="https://adamoudad.github.io/tags/embedding">embedding</a></li>
          
        </ul>
      </li>
    
  
</ul>

  </footer>
</article>

    <article class="post">
        <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "adamoudad-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </article>




<div class="pagination">
  
    <a href="/posts/vectorizing-text/" class="button"><div class="previous"><div>Vectorizing text</div></div></a>
  
  
    <a href="/posts/language/suru/" class="button"><div class="next"><div>Usages of する</div></div></a>
  
</div>


      </main>
      <section id="site-sidebar">
  
    <section id="recent-posts">
      <header>
        <h1>Recent posts</h1>
      </header>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/emacs/remote-command-ssh/">Run a command on a remote server with Emacs.</a></h1>
          <time class="published" datetime="">December 22, 2022</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/python-statements/">These Python keywords will simplify your code</a></h1>
          <time class="published" datetime="">October 16, 2022</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/pdfpc/">Keynote presentation on Linux</a></h1>
          <time class="published" datetime="">October 15, 2022</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/swap_control_caps/">Swap Control and Caps keys to relieve stress on the pinky</a></h1>
          <time class="published" datetime="">April 5, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
        <section>
          

        </section>
        <header>
          <h1><a href="/posts/keras_torch_comparison/sentiment_classification/">Comparing Keras and PyTorch on sentiment classification</a></h1>
          <time class="published" datetime="">March 20, 2021</time>
        </header>
      </article>
      
      
        <a href="/posts/" class="button">See more</a>
      
    </section>
  

  
    
      <section id="categories">
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
            
          
          
          <li>
            
              <a href="/categories/machine-learning/">machine-learning<span class="count">9</span></a>
            
          
          <li>
            
              <a href="/categories/programming/">programming<span class="count">6</span></a>
            
          
          <li>
            
              <a href="/categories/linux/">linux<span class="count">3</span></a>
            
          
          <li>
            
              <a href="/categories/natural-language-processing/">natural-language-processing<span class="count">3</span></a>
            
          
          <li>
            
              <a href="/categories/python/">python<span class="count">3</span></a>
            
          
          <li>
            
              <a href="/categories/emacs/">emacs<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/japanese/">japanese<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/security/">security<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/web/">web<span class="count">2</span></a>
            
          
          <li>
            
              <a href="/categories/computer/">computer<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/linguistic/">linguistic<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/random/">random<span class="count">1</span></a>
            
          
          <li>
            
              <a href="/categories/tools/">tools<span class="count">1</span></a>
            
          
          </li>
        </ul>
      </section>
    
  

  
    <section id="mini-bio">
      <header>
        <h1>About</h1>
      </header>
      <p>This website is a weblog were I write about computer science, machine learning, language learning.</p>
      <footer>
        <a href="/about" class="button">Learn More</a>
      </footer>
    </section>
  
</section>

      <footer id="site-footer">
  
      <ul class="socnet-icons">
        

        <li><a href="//github.com/adamoudad" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/7013114/adam-oudad" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@adam.oudad" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//linkedin.com/in/adamoudad" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>















<li><a href="//twitter.com/OudadAdam" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>







<li><a href="//researchgate.net/profile/Adam_Oudad" target="_blank" rel="noopener" title="Research Gate"><i class="ai ai-researchgate"></i></a></li>





      </ul>
  
  <p class="copyright">
    
      &copy; 2022
      
        (Machine) Learning log.
      
    . <br>
    Theme: <a href='https://github.com/pacollins/hugo-future-imperfect-slim' target='_blank' rel='noopener'>Hugo Future Imperfect Slim</a><br>A <a href='https://html5up.net/future-imperfect' target='_blank' rel='noopener'>HTML5 UP port</a> | Powered by <a href='https://gohugo.io/' title='0.99.1' target='_blank' rel='noopener'>Hugo</a>
  </p>
</footer>
<a id="back-to-top" href="#" class="fas fa-arrow-up fa-2x"></a>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css" integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js" integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js" integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>


      <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script><script src="/js/bundle.min.d0b3e0b5f2cfc7467ead7d316ecb9dea4d29ef3c23ad300df9d7017ff98b2331.js" integrity="sha256-0LPgtfLPx0Z&#43;rX0xbsud6k0p7zwjrTAN&#43;dcBf/mLIzE="></script>
    <script src="/js/add-on.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-150494000-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    </div>
  </body>
</html>
